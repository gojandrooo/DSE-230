{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d719acd",
   "metadata": {},
   "source": [
    "## Problem definition and data description\n",
    "\n",
    "### Problem Definition\n",
    "Our company (Spotify) would like to dynamically target advertising to non-premium members based on their physical activity while using Spotify services. For example, while a listener is enjoying a podcast and folding their laundry, they would receive an ad for laundry detergent. \n",
    "\n",
    "In addition Spotify also wishes to cater to our premium members by enhancing music recommendation/auto-play options based on a members physical activity. For example, while a user is exercising play up-tempo music, and while a user is eating pasta play Italian classics.\n",
    "\n",
    "### Data Description\n",
    "\n",
    "Accelerometer (measures proper acceleration) and Gyroscope (measures orientation and angular velocity) data was collected from 51 volunteer subjects. Each subject was asked to perform 18 tasks for 3 minutes each. The 18 tasks were a mix of physical activities that could be distinctly identified, such as walking, eating, laundry, etc. We (Spotify) tried to collect data for activities that our members might be doing while using our services. The tasks are listed below.\n",
    "\n",
    "![image info](./images/Activity-Code-Table.png)\n",
    "\n",
    "Each subject had a smartwatch placed on his/her dominant hand and a smartphone in their pocket. The smartphone and smartwatch both had an accelerometer and gyrocope, yielding four total sensors (Phone - Gyroscope, Phone - Accelerometer, Watch - Gyroscope, Watch - Accelerometer).\n",
    "\n",
    "![image info](./images/Human-With-Sensors.png)\n",
    "\n",
    "To accomodate the four sensors, the data is split up into 4 subdirectories, one for each device and sensor. \n",
    "\n",
    "![image info](./images/Sensor-Subdirectories.png)\n",
    "\n",
    "Each directory contains the sensor results for the 51 subject's performance of the 18 activities. The results for each subject are stored in a comma delimited text file. Since there are 51 subjects and 4 different sensors, there are a total of 204 text files. Each text file has the same six attributes: Subject-id, Activity Code, Timestamp, x, y, z\n",
    "\n",
    "![image info](./images/Raw-Data-Description.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79df222",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data preparation process\n",
    "\n",
    "Our data is pretty clean, we don't need to do a lot of preproccessing/data engineering. We really just need to do the ML side, which, lends itself more to the majority of work we need to do with this project. We stuck with dask so we could use the natural integration it has with python, as well as its similiar syntax to Pandas.\n",
    "\n",
    "To clean, prepare and train our data, we decided to go with dask. Our reasoning was that, while our data was large (approx. 15 million records, ~1 gb), it was not large enough to warrant the use of Spark. The image below summarizes our thoughts on the choice between dask vs spark.\n",
    "\n",
    "![image info](./images/Pandas-Dask-Spark-Compare.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ffdaf8",
   "metadata": {},
   "source": [
    "### Importing the data\n",
    "\n",
    "To shortstep the inconvenience of downloading and importing over 200 text files, we decided to host all the data on github for easy access (https://github.com/gojandrooo/DSE-230/tree/main/data). To quickly pull the github data into a pandas dataframe, we defined a function collate_df that will pull in all data matching the parameters given."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cebfd8-9efe-40e3-ac5a-f5a8fe804009",
   "metadata": {},
   "source": [
    "Begin by importing all the necessary libraries\n",
    "\n",
    "Running within *Docker* container you will need to install libraries not already included in the image.\n",
    "- comment/uncomment the `%pip install` cell (below)\n",
    "- run the cell, wait for the packages to install, and then restart notebook. \n",
    "- once installs are complete, comment out the cell and run all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0147ccf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Downloading plotly-5.8.0-py2.py3-none-any.whl (15.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.2 MB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tenacity, plotly\n",
      "Successfully installed plotly-5.8.0 tenacity-8.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting dask_distance\n",
      "  Downloading dask-distance-0.2.0.tar.gz (35 kB)\n",
      "Requirement already satisfied: dask in /usr/local/lib/python3.8/dist-packages (from dask_distance) (2022.4.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from dask_distance) (1.21.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.8/dist-packages (from dask->dask_distance) (0.11.2)\n",
      "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.8/dist-packages (from dask->dask_distance) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from dask->dask_distance) (21.3)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from dask->dask_distance) (2022.3.0)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from dask->dask_distance) (2.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from dask->dask_distance) (5.4.1)\n",
      "Requirement already satisfied: locket in /usr/local/lib/python3.8/dist-packages (from partd>=0.3.10->dask->dask_distance) (1.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->dask->dask_distance) (3.0.8)\n",
      "Building wheels for collected packages: dask-distance\n",
      "  Building wheel for dask-distance (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dask-distance: filename=dask_distance-0.2.0-py2.py3-none-any.whl size=9069 sha256=bcf5b00d36272d4024496ace836437c49250d4a5be1415e690b53c8aa61acb27\n",
      "  Stored in directory: /home/.cache/pip/wheels/7f/1a/8f/7f5269f3670f46d69b900921a8f06f7592daf09572ea27865b\n",
      "Successfully built dask-distance\n",
      "Installing collected packages: dask-distance\n",
      "Successfully installed dask-distance-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install plotly\n",
    "%pip install dask_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18a17cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set a random state seed for replication\n",
    "seed=23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b55ef5e0-4738-475f-b0a9-b986a2bed255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "\n",
    "# plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# distributed libraries\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "from dask.distributed import Client\n",
    "from dask import delayed\n",
    "import joblib\n",
    "\n",
    "# model processing libraries\n",
    "import dask_distance\n",
    "from dask_ml.model_selection import train_test_split\n",
    "from dask_ml.preprocessing import StandardScaler\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "import dask_ml.model_selection as dcv\n",
    "\n",
    "# models\n",
    "# will need to update these with the models we use\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import ssl\n",
    "# needed to request files from GitHub when running within docker container\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31b49c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 21:48:17,276 - distributed.diskutils - INFO - Found stale lock file and directory '/home/work/dask-worker-space/worker-bfi8y_8c', purging\n",
      "2022-05-23 21:48:17,338 - distributed.diskutils - INFO - Found stale lock file and directory '/home/work/dask-worker-space/worker-fm5npyq2', purging\n",
      "2022-05-23 21:48:17,347 - distributed.diskutils - INFO - Found stale lock file and directory '/home/work/dask-worker-space/worker-x2rkz5h9', purging\n",
      "2022-05-23 21:48:17,355 - distributed.diskutils - INFO - Found stale lock file and directory '/home/work/dask-worker-space/worker-yvhjs1s8', purging\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ssl_context': None, 'require_encryption': False, 'extra_conn_args': {}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start and connect to a local dask.distributed client\n",
    "client = Client()\n",
    "client.connection_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df2fa91-a025-45e3-8a66-e26a11ab5ead",
   "metadata": {},
   "source": [
    "Get data from github and prep files for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11a388e6-a2ad-444b-86c0-e44fcbaa346e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# key for understanding which activity is being measured in a record\n",
    "activity_key_url = r\"https://raw.githubusercontent.com/gojandrooo/DSE-230/main/data/activity_key.txt\"\n",
    "\n",
    "#read the activity table from gtihub\n",
    "activity_key = pd.read_csv(activity_key_url, header=None)\n",
    "\n",
    "#split the data into a proper table\n",
    "activity_key = activity_key[0].str.replace(\" \", \"\").str.split(\"=\", expand=True)\n",
    "activity_key.columns = ['activity', 'code']\n",
    "#activity_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2220f631-cb75-4821-9047-17485d0e8ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#below function takes the raw data on githup and converts to parquet files\n",
    "#then stores the files on local machine\n",
    "\n",
    "def convert_raw_to_parquet():\n",
    "    #base URL where raw data can be easly grabbed\n",
    "    base_url = r\"https://raw.githubusercontent.com/gojandrooo/DSE-230/main/data\"\n",
    "\n",
    "    # TOGGLE FOR DEVICE\n",
    "    devices = [\"phone\", \"watch\"]\n",
    "\n",
    "    # TOGGLE FOR MEASUREMENT TYPE\n",
    "    data_types = [\"accel\", \"gyro\"]\n",
    "    \n",
    "    \n",
    "    # create list of local folders\n",
    "    for data_type in data_types:\n",
    "        for device in devices:\n",
    "            os.makedirs(r\"data/parquet/\" + \"/\" + device + \"/\" + data_type, exist_ok=True) \n",
    "    \n",
    "\n",
    "    locs = {}\n",
    "    for data_type in data_types:\n",
    "        for device in devices:\n",
    "            file_locs = []\n",
    "            for user_id in range(1600, 1651):\n",
    "                url = base_url + \"/\" + device + \"/\" + data_type + f\"/data_{user_id}_{data_type}_{device}.txt\"\n",
    "                df = pd.read_csv(url, header=None)\n",
    "                df.columns = ['subject_id', 'code', 'timestamp', 'x', 'y', 'z']\n",
    "                df['z'] = df['z'].str.replace(\";\", \"\").astype('float64')\n",
    "                #df = df.reset_index(drop = True)\n",
    "                df['index'] = df['subject_id'].astype('str') + df['code'] + df['timestamp'].astype('str')\n",
    "                fname = r\"data/parquet/\" + \"/\" + device + \"/\" + data_type + f\"/data_{user_id}_{data_type}_{device}.gzip\"\n",
    "                df.to_parquet(fname)\n",
    "                file_locs.append(fname)\n",
    "            locs[device, data_type] = file_locs\n",
    "    return locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aa25aa71-2a08-4952-8a52-4b64093c7348",
   "metadata": {},
   "outputs": [],
   "source": [
    "locs = convert_raw_to_parquet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3317d049-5d95-415b-9558-df056e0925aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "255b56ba-b7f2-48b4-8eaf-24f9d2465c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dask_df = dd.multi.concat([dd.read_parquet(file, index='index', infer_divisions=True) for file in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d8aa2ce2-9413-4178-aa39-38902dc99363",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dask_df.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de3c4388-9f67-4b01-acbc-4e218c5c88fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE\n",
    "# this still only grabs three spreadsheets, update for production\n",
    "\n",
    "def collate_dask_df(device, data_type):\n",
    "\n",
    "    '''\n",
    "    returns a single dask dataframe from multiple text files hosted on github\n",
    "    \n",
    "    device: [\"phone\", \"watch\"]\n",
    "    \n",
    "    data_type: [\"accel\", \"gyro\"]\n",
    "    ----------------------------\n",
    "    '''\n",
    "    \n",
    "    base_url = r\"https://raw.githubusercontent.com/gojandrooo/DSE-230/main/data\"\n",
    "\n",
    "    # TOGGLE FOR DEVICE\n",
    "    device = device\n",
    "\n",
    "    # TOGGLE FOR MEASUREMENT TYPE\n",
    "    data_type = data_type\n",
    "    \n",
    "    # create list of all file names\n",
    "    file_names = [f\"/data_{user_id}_{data_type}_{device}.txt\" for user_id in range(1600, 1651)]\n",
    "\n",
    "    # create urls of all files\n",
    "    loop_urls = [base_url + \"/\" + device + \"/\" + data_type + file_name for file_name in file_names]\n",
    "    \n",
    "    # concatenate data into one object\n",
    "    '''still uses `pandas.read_csv` instead of `dask.read_csv` due to certificate issue'''\n",
    "    #dask_df = dd.multi.concat([pd.read_csv(url, header=None) for url in loop_urls[:3]]) # for dev this is only the first three files\n",
    "    dask_df = dd.multi.concat([pd.read_csv(url, header=None) for url in loop_urls]) # PRODUCTION, all of the files\n",
    "    \n",
    "    dask_df.columns = ['subject_id', 'code', 'timestamp', 'x', 'y', 'z']\n",
    "    dask_df['z'] = dask_df['z'].str.replace(\";\", \"\").astype('float64')\n",
    "    dask_df = dask_df.reset_index(drop = True)\n",
    "    \n",
    "    return dask_df # dask df output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffc71f2-74e5-4a7e-83bb-a0364b16e560",
   "metadata": {},
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95c6e6fc-3eed-42b6-b378-726418d988ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.8 s, sys: 10 s, total: 33.9 s\n",
      "Wall time: 4min 18s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>code</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1600</td>\n",
       "      <td>A</td>\n",
       "      <td>252207666810782</td>\n",
       "      <td>-0.364761</td>\n",
       "      <td>8.793503</td>\n",
       "      <td>1.055084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1600</td>\n",
       "      <td>A</td>\n",
       "      <td>252207717164786</td>\n",
       "      <td>-0.879730</td>\n",
       "      <td>9.768784</td>\n",
       "      <td>1.016998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1600</td>\n",
       "      <td>A</td>\n",
       "      <td>252207767518790</td>\n",
       "      <td>2.001495</td>\n",
       "      <td>11.109070</td>\n",
       "      <td>2.619156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id code        timestamp         x          y         z\n",
       "0        1600    A  252207666810782 -0.364761   8.793503  1.055084\n",
       "1        1600    A  252207717164786 -0.879730   9.768784  1.016998\n",
       "2        1600    A  252207767518790  2.001495  11.109070  2.619156"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# create the dask dataframes for each sensor\n",
    "phone_accel = collate_dask_df(\"phone\", \"accel\")\n",
    "phone_gyro = collate_dask_df(\"phone\", \"gyro\")\n",
    "watch_accel = collate_dask_df(\"watch\", \"accel\")\n",
    "watch_gyro = collate_dask_df(\"watch\", \"gyro\")\n",
    "phone_accel.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba34c0c-700d-4952-b4d9-42bd0a843572",
   "metadata": {},
   "source": [
    "### Preparing the data for merging/grouping\n",
    "Adding custom index so merge is more efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2fa704a-40f2-4556-9a9c-de599dff37bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.8 ms, sys: 2.08 ms, total: 22.9 ms\n",
      "Wall time: 18.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#set custom index for joining\n",
    "#joining on an index in dask optimizes the operation\n",
    "#might be even faster if we create this column during the data ingestion phase of collate_dask_df\n",
    "phone_accel['index'] = phone_accel['subject_id'].astype('str') + phone_accel['code'] + phone_accel['timestamp'].astype('str')\n",
    "phone_gyro['index'] = phone_gyro['subject_id'].astype('str') + phone_gyro['code'] + phone_gyro['timestamp'].astype('str')\n",
    "watch_accel['index'] = watch_accel['subject_id'].astype('str') + watch_accel['code'] + watch_accel['timestamp'].astype('str')\n",
    "watch_gyro['index'] = watch_gyro['subject_id'].astype('str') + watch_gyro['code'] + watch_gyro['timestamp'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21c8f863-e82f-4481-bae1-3aa28d5aa114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.68 s, sys: 602 ms, total: 5.29 s\n",
      "Wall time: 13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "phone_accel = phone_accel.set_index('index')\n",
    "phone_gyro = phone_gyro.set_index('index')\n",
    "watch_accel = watch_accel.set_index('index')\n",
    "watch_gyro = watch_gyro.set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef6e560b-ce9b-4698-a449-c0724845b4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-0d04e4f7-dae2-11ec-81c7-0242ac110002</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> distributed.LocalCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:8787/status\" target=\"_blank\">http://127.0.0.1:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">LocalCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">1d183909</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:8787/status\" target=\"_blank\">http://127.0.0.1:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 4\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 8\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 7.77 GiB\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "    <td style=\"text-align: left;\"><strong>Status:</strong> running</td>\n",
       "    <td style=\"text-align: left;\"><strong>Using processes:</strong> True</td>\n",
       "</tr>\n",
       "\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-3edb6259-43cb-4015-ae69-db9a755ca4aa</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://127.0.0.1:37633\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 4\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:8787/status\" target=\"_blank\">http://127.0.0.1:8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 8\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> 4 minutes ago\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 7.77 GiB\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 0</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:36849\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 2\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:43161/status\" target=\"_blank\">http://127.0.0.1:43161/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 1.94 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:41575\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /home/work/dask-worker-space/worker-p8ihk_si\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 1</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:42949\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 2\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:41061/status\" target=\"_blank\">http://127.0.0.1:41061/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 1.94 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:44311\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /home/work/dask-worker-space/worker-1z3dtgqt\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 2</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:43969\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 2\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:39409/status\" target=\"_blank\">http://127.0.0.1:39409/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 1.94 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:36763\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /home/work/dask-worker-space/worker-qgt_eenp\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 3</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:34337\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 2\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:44085/status\" target=\"_blank\">http://127.0.0.1:44085/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 1.94 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:46207\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /home/work/dask-worker-space/worker-io6s6xq6\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:37633' processes=4 threads=8, memory=7.77 GiB>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4411dbd9-cbb4-4bad-a8b6-741289f9ea51",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = ['x', 'y', 'z']\n",
    "def merge_dfs(df1, df2, suffixes):\n",
    "    df1partitions = df1.npartitions\n",
    "    df2partitions = df2.npartitions\n",
    "    partitions = max(df1partitions, df2partitions)\n",
    "    merged =  dd.merge(df1, df2[feat_cols], how='inner', left_index = True, right_index = True, \n",
    "                    suffixes=suffixes).reset_index(drop = True)\n",
    "    return dd.from_pandas(merged.compute(), npartitions = partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2255eba3-b992-439a-abe9-94ef389ba5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt to merge phone data\n",
    "phone_df = merge_dfs(phone_accel, phone_gyro[feat_cols], ('_phone_accel', '_phone_gyro'))\n",
    "phone_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3c938e-a10e-4af4-9681-6384efbe5fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt to merge watch data\n",
    "watch_df = merge_dfs(watch_accel, watch_gyro[feat_cols], ('_watch_accel', '_watch_gyro'))\n",
    "watch_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d33a17-5842-4d84-afaf-d9281ec09b68",
   "metadata": {
    "tags": []
   },
   "source": [
    "### EDA\n",
    "Below we compare the accelerometer sensors results and the gyroscope results independently. This is because the sensors have different units. The accelerometer sensor has units in m/s^2 while the gyroscope has units in radians/s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376d6626-9d99-44dc-bec8-66d6ee200851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZE DATA\n",
    "# just a sample\n",
    "\n",
    "# depending on your setup may need different renderer to display\n",
    "# iframe should render on local implementation and docker image implementation\n",
    "\n",
    "renderer = [\n",
    "    'notebook', # local\n",
    "    'notebook_connected', # local\n",
    "    'kaggle', # local\n",
    "    'azure', # local\n",
    "    'browser', # local (opens plot in new browser tab)\n",
    "    'iframe', # docker, local (saves plot in `iframe_figures` folder)\n",
    "    'iframe_connected', # docker, local (saves plot in `iframe_figures` folder)\n",
    "    'colab' # docker\n",
    "]\n",
    "\n",
    "# take a sample of the data\n",
    "df = phone_accel.sample(frac=0.2, random_state=seed).sort_values(by='code').compute()\n",
    "fig = px.scatter_3d(df, \n",
    "                    x='x', \n",
    "                    y='y', \n",
    "                    z='z',\n",
    "                    color='code')\n",
    "fig.show(renderer=renderer[-2]) # if plot does not render, try a different index, the last three are preferred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcf65c5-9fc1-4670-8ec4-b9ef66314c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = ['x', 'y', 'z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844eec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_accel_stats, watch_accel_stats = dask.compute(\n",
    "    phone_accel[feat_cols].describe(),\n",
    "    watch_accel[feat_cols].describe()    \n",
    "    )\n",
    "accel_stats = phone_accel_stats.merge(watch_accel_stats, left_index=True, right_index=True, suffixes=('_phone_accel', '_watch_accel'))\n",
    "accel_stats.reindex(sorted(accel_stats.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eced70",
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_gyro_stats, watch_gyro_stats = dask.compute(\n",
    "    phone_gyro[feat_cols].describe(),\n",
    "    watch_gyro[feat_cols].describe()    \n",
    "    )\n",
    "gyro_stats = phone_gyro_stats.merge(watch_gyro_stats, left_index=True, right_index=True, suffixes=('_phone_gyro', '_watch_gyro'))\n",
    "gyro_stats.reindex(sorted(gyro_stats.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239289fe-d6df-4eba-bae7-64d57cc5198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del phone_accel_stats\n",
    "del watch_accel_stats\n",
    "del phone_gyro_stats\n",
    "del watch_gyro_stats\n",
    "del accel_stats\n",
    "del gyro_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d89a7b4-7a4c-4c03-8a96-5eff565bcd8b",
   "metadata": {},
   "source": [
    "# <font color='red'>Don't run this! With full data its killing the memory</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0046f33-87de-4583-b451-75ce87e06275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT HISTOGRAMS\n",
    "# calculate the histograms using the dask dataframes\n",
    "# since dask deals with large data we cant easily graph the dataframe\n",
    "# need to get all the histograms by hand and plot\n",
    "\n",
    "sensor_dfs = [phone_accel, watch_accel, phone_gyro,  watch_gyro]\n",
    "sensor_labels = ['phone_accel', 'watch_accel', 'phone_gyro',  'watch_gyro']\n",
    "\n",
    "def hist_subplot(dask_df, axis, n_bins, data_label, ax_row, ax_col):\n",
    "    '''\n",
    "    helper function to plot histograms\n",
    "    \n",
    "    dask_df: underlying dataframe\n",
    "    \n",
    "    axis: ['x', 'y', 'z']\n",
    "    \n",
    "    n_bins: int\n",
    "    \n",
    "    ax_row: subplot location\n",
    "    ax_col: subplot location\n",
    "    '''  \n",
    "    h, bins = da.histogram(dask_df[axis], bins=n_bins, range=[dask_df[axis].min().compute(), dask_df[axis].max().compute()])\n",
    "    bincenter = (bins[:-1] + bins[1:]) / 2\n",
    "    axes[ax_row,ax_col].bar(bincenter, list(h.compute()), align='center', width=2, alpha=0.65, label = data_label)\n",
    "    axes[ax_row,ax_col].legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2c618f-e941-4e6b-a8c6-a6bfa26bb18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we have the function, actually plot the data\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, sharex=True, sharey=True, figsize=(14,12))\n",
    "    \n",
    "# x-axis - firt row of subplot\n",
    "axis = 'x'\n",
    "i = 0\n",
    "hist_subplot(sensor_dfs[i], axis, 20, sensor_labels[i], 0, 0)\n",
    "i = 1\n",
    "hist_subplot(sensor_dfs[i], axis, 20, sensor_labels[i], 0, 0)\n",
    "i = 2\n",
    "hist_subplot(sensor_dfs[i], axis, 20, sensor_labels[i], 0, 1)\n",
    "i = 3\n",
    "hist_subplot(sensor_dfs[i], axis, 20, sensor_labels[i], 0, 1)\n",
    "\n",
    "# y-axis - second row of subplot\n",
    "axis = 'y'\n",
    "i = 0\n",
    "hist_subplot(sensor_dfs[i], axis, 20, sensor_labels[i], 1, 0)\n",
    "i = 1\n",
    "hist_subplot(sensor_dfs[i], axis, 20, sensor_labels[i], 1, 0)\n",
    "i = 2\n",
    "hist_subplot(sensor_dfs[i], axis, 20, sensor_labels[i], 1, 1)\n",
    "i = 3\n",
    "hist_subplot(sensor_dfs[i], axis, 20, sensor_labels[i], 1, 1)\n",
    "\n",
    "# z-axis - third row of subplot\n",
    "axis = 'z'\n",
    "i = 0\n",
    "hist_subplot(sensor_dfs[i], axis, 20, sensor_labels[i], 2, 0)\n",
    "i = 1\n",
    "hist_subplot(sensor_dfs[i], axis, 20, sensor_labels[i], 2, 0)\n",
    "i = 2\n",
    "hist_subplot(sensor_dfs[i], axis, 20, sensor_labels[i], 2, 1)\n",
    "i = 3\n",
    "hist_subplot(sensor_dfs[i], axis, 20, sensor_labels[i], 2, 1)\n",
    "\n",
    "axes[0,0].set_title('Phone/Watch Accelerometer')\n",
    "axes[0,1].set_title('Phone/Watch Gyroscope')\n",
    "\n",
    "plt.setp(axes[0, :], ylabel='x-axis')\n",
    "plt.setp(axes[1, :], ylabel='y-axis')\n",
    "plt.setp(axes[2, :], ylabel='z-axis')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d545879-fef8-4f32-9f8b-a211c0bcefaf",
   "metadata": {},
   "source": [
    "Before merging, each of the activities was roughly balanced with each otiher. The `watch` sensors are unaffected, but merging the accel/gyro sensors for the `phone` created a slighty misbalance. However, it is not to the point that it will create problems for our classification modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa90effa-b507-4093-8af8-64c1cab2cedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect whether our classes are still balanced\n",
    "\n",
    "activity_distr = pd.DataFrame(dask.compute(\n",
    "    phone_df['code'].value_counts(normalize=True),\n",
    "    watch_df['code'].value_counts(normalize=True)\n",
    "    )).T\n",
    "activity_distr.columns = ['phone', 'watch']\n",
    "activity_distr.style.format(\"{:,.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fe23dc-cab4-48b5-8829-06c1ea2aca99",
   "metadata": {},
   "source": [
    "### Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8e378b-9b29-45a4-9c6a-04e0c2395436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maybe we won't even do this. if we do, we need to define train_test_split up here\n",
    "'''\n",
    "code for scaling is at the ML stage if we want to move it up here\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc8d17c-a335-4bf6-a92a-12ccea7a275a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Aggregating the data\n",
    "\n",
    "the raw data is time series measurements, for our model, we want to aggregate the data to n-second intervals with with we can make predictions. We selected 3-seconds as the time for a task to be performed and make a prediction\n",
    "\n",
    "- within each n_second agregation, map relationship between each of the x/y/x paired arrays\n",
    "    - COSINE\n",
    "        - xy\n",
    "        - xz\n",
    "        - yz\n",
    "    - CORRELATION\n",
    "        - xy\n",
    "        - xz\n",
    "        - yz\n",
    "- Calculate AVERAGES\n",
    "    - x-mean\n",
    "    - y-mean\n",
    "    - z-mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9138a44b-639e-4fdf-889f-23b07583847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6889871-d62e-4b64-8e19-5b9bd124352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_combos = list(it.combinations(feat_cols, 2))\n",
    "col_combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc82459c-7063-4622-9040-68d23dcc90e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to calculate the pairwise metrics for out features\n",
    "def cos_cor_combos(dask_df, cols):\n",
    "    '''\n",
    "    calculate the cosine similarity and the correlation coefficient for two arrays\n",
    "    '''\n",
    "    cos, cor = dask.compute(\n",
    "        #dask_distance.chebyshev(dask_df[cols[0]], dask_df[cols[1]]),\n",
    "        dask_distance.cosine(dask_df[cols[0]], dask_df[cols[1]]),\n",
    "        dask_distance.correlation(dask_df[cols[0]], dask_df[cols[1]])\n",
    "        )\n",
    "    return cos, cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3581eda0-67b3-4d48-9125-50f1ad3d324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "not actual implementation, just wireframe guide\n",
    "'''\n",
    "for combo in col_combos:\n",
    "    print(combo, \":\", cos_cor_combos(phone_accel.head(10), combo))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58886261-c0a2-487a-9aef-803db4b30285",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### some helpful reference materials <font color='red'>delete later<font>\n",
    "\n",
    "inefficient: loop over grouper\n",
    "    for group in grouper:\n",
    "        compute cosine\n",
    "        \n",
    "[df.apply from SO](https://stackoverflow.com/questions/45535892/calculate-cosine-similarity-for-two-columns-in-a-group-by-in-a-dataframe)\n",
    "\n",
    "[dask delayed inside for loop](https://stackoverflow.com/questions/42550529/dask-how-would-i-parallelize-my-code-with-dask-delayed)\n",
    "\n",
    "```python\n",
    "from dask import compute, delayed\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "filenames = [...]\n",
    "\n",
    "def compute_mse(file_name):\n",
    "    df = pd.read_csv(file_name)\n",
    "    prediction = df['Close'][:-1]\n",
    "    observed = df['Close'][1:]\n",
    "    return mse(observed, prediction)\n",
    "\n",
    "# DASK DELAYED EXAMPLE SYNTAX\n",
    "delayed_results = [delayed(compute_mse)(file_name) for file_name in filenames]\n",
    "mean_squared_errors = compute(*delayed_results, scheduler=\"processes\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edd95d1-8384-4586-8ab8-348e15b9c900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create combinations for each of our features\n",
    "\n",
    "accel_feats = ['x_phone_accel', 'y_phone_accel', 'z_phone_accel']\n",
    "gryo_feats = ['x_phone_gyro', 'y_phone_gyro', 'z_phone_gyro']\n",
    "\n",
    "accel_combos = list(it.combinations(accel_feats, 2))\n",
    "gyro_combos = list(it.combinations(gryo_feats, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cab47f-234c-42df-bbd4-c9842fe8cded",
   "metadata": {},
   "outputs": [],
   "source": [
    "accel_combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8228779-ad4c-4d85-bcc5-daa043e54334",
   "metadata": {},
   "outputs": [],
   "source": [
    "gyro_combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0770d989-dc96-4e1b-86df-7a3e448fbd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_cor_aggregation(df, num_seconds, partitions):\n",
    "    '''\n",
    "    function to compute the cosine and correlation for each of the feature pairs within each of the time subdivisions\n",
    "    '''  \n",
    "    n_rows = (num_seconds*1000)/50\n",
    "    print('Grouped every', n_rows, 'rows')\n",
    "    \n",
    "    tempdf = df.reset_index()\n",
    "    # rename of the index column\n",
    "    tempdf = tempdf.rename(columns={'index': 'grouper'})\n",
    "\n",
    "    # creates a variable to group within n_seconds\n",
    "    tempdf['grouper'] = tempdf['grouper']//n_rows\n",
    "\n",
    "    # # RELATIONSHIP FEATURES\n",
    "    # (two approaches, Loop Method vs Apply Method)\n",
    "\n",
    "    # LOOP METHOD - did not work at scale\n",
    "    \n",
    "    # ACCELEROMETER\n",
    "    # for combo in accel_combos:\n",
    "\n",
    "    #     delayed_results = [delayed(cos_cor_combos)(group, combo) for name, group in tempdf.groupby(['grouper', 'subject_id', 'code'])]\n",
    "    #     output = dd.compute(*delayed_results, scheduler=\"processes\")\n",
    "\n",
    "    #     for name, group in tempdf.groupby(['grouper', 'subject_id', 'code']):\n",
    "    #         print(cos_cor_combos(group, combo))\n",
    "\n",
    "    # # GYROSCOPE\n",
    "    # for combo in gyro_combos:\n",
    "    #     for name, group in tempdf.groupby(['grouper', 'subject_id', 'code']):\n",
    "    #         print(cos_cor_combos(group, combo))\n",
    "\n",
    "\n",
    "    # APPLY METHOD - technically works but is slow af\n",
    "    '''\n",
    "    there is likely room for performance improvement with increased parallelization\n",
    "    change the initial dataframes from pandas to dask\n",
    "    '''\n",
    "    # ACCELEROMETER\n",
    "    # instantiate empty dataframe to build on\n",
    "    accel_new_feat_df = pd.DataFrame()\n",
    "\n",
    "    for combo in accel_combos:\n",
    "        new_col_name = \"-\".join(combo) # for naming columns in the returned output  \n",
    "        # calculate the metrics for our subdivisions of data\n",
    "        new_feat_temp = tempdf.groupby(['grouper', 'subject_id', 'code']).apply(lambda g: cos_cor_combos(tempdf, combo))\n",
    "        # create a dataframe with the new features\n",
    "        accel_new_feat_df[['cos-'+new_col_name, 'cor-'+new_col_name]] = pd.DataFrame(new_feat_temp)[0].to_list()\n",
    "        # create the dask df\n",
    "        #n_partitions = accel_new_feat_df.npartitions\n",
    "        accel_new_feat_dd = dd.from_pandas(accel_new_feat_df, npartitions=partitions)\n",
    "    \n",
    "    # GYROSCOPE\n",
    "    # instantiate empty dataframe to build on\n",
    "    gyro_new_feat_df = pd.DataFrame()\n",
    "\n",
    "    for combo in gyro_combos:\n",
    "        new_col_name = \"-\".join(combo) # for naming columns in the returned output\n",
    "        # calculate the metrics for our subdivisions of data\n",
    "        '''\n",
    "        new_feat_temp = tempdf.groupby(['grouper', 'subject_id', 'code']).apply(lambda g: cos_cor_combos(tempdf, combo))\n",
    "        '''\n",
    "        # create a dataframe with the new features\n",
    "        gyro_new_feat_df[['cos-'+new_col_name, 'cor-'+new_col_name]] = pd.DataFrame(new_feat_temp)[0].to_list()\n",
    "        # create the dask df\n",
    "        #n_partitions = gyro_new_feat_df.npartitions\n",
    "        '''\n",
    "        I think we might be able to get away with just keeping it as pandas since the aggregate df will be much smaller\n",
    "        '''\n",
    "        gyro_new_feat_dd = dd.from_pandas(gyro_new_feat_df, npartitions=partitions)\n",
    "    \n",
    "    # MERGE SENSOR TYPES\n",
    "    created_feats = dd.merge(\n",
    "        accel_new_feat_dd, \n",
    "        gyro_new_feat_dd, \n",
    "        how='inner', \n",
    "        left_index = True, \n",
    "        right_index = True, \n",
    "            )\n",
    "    return created_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724efd5b-4a75-4560-b201-e21299dc1066",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# test the function\n",
    "# note it's just executing on a sample of the data `.head(1000)`\n",
    "synth_feats = cos_cor_aggregation(phone_df.head(1000), 3, 64) # experiment with larger number of partitions\n",
    "\n",
    "print(dd.compute(synth_feats.shape))\n",
    "synth_feats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3613cac7-967a-4d13-8158-69788f98e71b",
   "metadata": {},
   "source": [
    "# <font color='red'>Proposed alt way of getting cos and cor</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e77cb19-1585-4c38-9ec7-5dc43a8def90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiply the accel columns together\n",
    "phone_df['xy_phone_accel'] = phone_df['x_phone_accel']*phone_df['y_phone_accel']\n",
    "phone_df['yz_phone_accel'] = phone_df['y_phone_accel']*phone_df['z_phone_accel']\n",
    "phone_df['xz_phone_accel'] = phone_df['x_phone_accel']*phone_df['z_phone_accel']\n",
    "\n",
    "phone_df['xy_phone_gyro'] = phone_df['x_phone_gyro']*phone_df['y_phone_gyro']\n",
    "phone_df['yz_phone_gyro'] = phone_df['y_phone_gyro']*phone_df['z_phone_gyro']\n",
    "phone_df['xz_phone_gyro'] = phone_df['x_phone_gyro']*phone_df['z_phone_gyro']\n",
    "\n",
    "phone_df['x_phone_accel^2'] = phone_df['x_phone_accel']**2\n",
    "phone_df['y_phone_accel^2'] = phone_df['y_phone_accel']**2\n",
    "phone_df['z_phone_accel^2'] = phone_df['z_phone_accel']**2\n",
    "\n",
    "phone_df['x_phone_gyro^2'] = phone_df['x_phone_gyro']**2\n",
    "phone_df['y_phone_gyro^2'] = phone_df['y_phone_gyro']**2\n",
    "phone_df['z_phone_gyro^2'] = phone_df['z_phone_gyro']**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cac3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes the combined sensor data and bins the data by taking the average depending on the seconds required\n",
    "\n",
    "def group_into_seconds(df, num_seconds):\n",
    "    # calculates the number of rows to average over by converting seconds to ms and diving by 50 (sensor interval)\n",
    "    \n",
    "    n_rows = (num_seconds*1000)/50\n",
    "    print('Grouped every', n_rows, 'rows')\n",
    "    \n",
    "    tempdf = df.reset_index()\n",
    "    # rename of the index column\n",
    "    tempdf = tempdf.rename(columns= {'index': 'grouper'})\n",
    "    \n",
    "    # creates a variable to group within n_seconds\n",
    "    tempdf['grouper'] = tempdf['grouper']//n_rows\n",
    "    \n",
    "    # aggregate to n_seconds\n",
    "    tempdf = tempdf.groupby(by = ['grouper', 'code', 'subject_id']).agg(['mean', 'sum']).reset_index()\n",
    "    # drop superflous grouper column\n",
    "    del tempdf['grouper']\n",
    "    tempdf.columns = list(map(''.join, tempdf.columns.values))\n",
    "    \n",
    "    return tempdf\n",
    "    # return df.groupby(np.arange(len(df))//n_rows).mean().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce4c18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#just testing to make sure it returns the same exact data frame when growing rows = 1\n",
    "#group_into_seconds(phone_df.compute(),50/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe8b566-560f-4122-9674-c77865724aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_into_seconds(phone_df.compute(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d4a889-b95d-40c0-bd39-f601c84e7c18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pass this variable in to all our aggregation functions\n",
    "# it is the number of seconds we are aggregating to\n",
    "agg_time = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62387d80-6024-4027-a237-42ffa4c2715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the averages within our time interval\n",
    "grouped_phone_df, grouped_watch_df = dask.compute(\n",
    "    group_into_seconds(phone_df, agg_time),\n",
    "    group_into_seconds(watch_df, agg_time)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfa4dd6-89fc-4bfa-bfe8-eac0fb523042",
   "metadata": {},
   "source": [
    "# <font color='red'>warning - this is when it gets REALLY slow</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e1c98f-6d19-4978-8cd9-694165ddd8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the created features within our time interval\n",
    "synth_phone_df, synth_watch_df = dask.compute(\n",
    "    cos_cor_aggregation(phone_df, agg_time, 64),\n",
    "    cos_cor_aggregation(watch_df, agg_time, 64)\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d708c53-3d3b-4a29-8cbe-b3d105cf70c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "merge grouped averages with synthetic features\n",
    "they must be the same shapes\n",
    "we also need to test for unexpected shuffling behavior\n",
    "'''\n",
    "\n",
    "# merge the new features from each sensor into one df\n",
    "prepped_phone_df = dd.merge(\n",
    "    grouped_phone_df, \n",
    "    synth_phone_df, \n",
    "    how='inner', \n",
    "    left_index = True, \n",
    "    right_index = True, \n",
    "        )\n",
    "\n",
    "prepped_watch_df = dd.merge(\n",
    "    grouped_watch_df, \n",
    "    synth_watch_df, \n",
    "    how='inner', \n",
    "    left_index = True, \n",
    "    right_index = True, \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2978a09-797e-4491-99d7-554a1fc49823",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.compute(prepped_phone_df.shape, prepped_watch_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e64aa86-8947-46fb-a901-65238a247e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepped_phone_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e693536c-c801-412e-90be-5cd6c18b36b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepped_watch_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da4b0de-1aa5-4f20-9b5d-845b3b96c0f0",
   "metadata": {},
   "source": [
    "### create csv files for faster recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5635085d-9020-49c5-980e-5a31a1f31e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out file to csv\n",
    "file_name = 'prepped_phone_df'\n",
    "df = prepped_phone_df\n",
    "# should output as .csv to retain data structure\n",
    "df.to_csv(fr'./prepped-data/{file_name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b791620-5998-489a-aa66-e0ecb4df23eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out file to csv\n",
    "file_name = 'prepped_watch_df'\n",
    "df = prepped_watch_df\n",
    "# should output as .csv to retain data structure\n",
    "df.to_csv(fr'./prepped-data/{file_name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8174665f-ad69-469f-a477-4a7e51511120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write out to excel (wireframe)\n",
    "# file_name = 'file_name'\n",
    "# writer = pd.ExcelWriter(f'{file_name}.xlsx', engine='xlsxwriter')\n",
    "# df.to_excel(writer, sheet_name='sheet-name')\n",
    "# writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758bf009-9308-4ec8-b5ee-5d89b592ff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # output the to .tsv/csv (wireframe)\n",
    "# file_name = 'file_name'\n",
    "# df = df#.astype(str) #preserve dtype with str if not already\n",
    "# # should output as .tsv to retain data structure\n",
    "# df.to_csv(fr'{file_name}.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ecebc4-e200-4539-88ad-29fff80f87b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # serialize file (wireframe)\n",
    "# file_name = 'file_name'\n",
    "# df = df\n",
    "# df.to_pickle(f\"./{file_name}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb80f82-d595-4052-8525-1e3eda61628f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read serialized file (wireframe)\n",
    "# file_name = 'file_name'\n",
    "# unpickled_df = pd.read_pickle(f\"./{file_name}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a70ec8-7038-431c-9d2f-c2fd5dc775b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncompress file and read in to dask (wireframe)\n",
    "# file_name = 'file_name'\n",
    "# unpickled_df = pd.read_pickle(f\"./{file_name}.pkl\")\n",
    "# ddf = dd.from_pandas(unpickled_df, npartitions=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7c3ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read in file as a dask dataframe\n",
    "# phone_accel = dd.read_csv(f\"prepped-data/{file_name}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fd078d",
   "metadata": {},
   "source": [
    "**<font color='red'>I don't think we actually need hadoop. saving in case we do and/or syntax for running other  bash commands</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657f6293-0a42-4880-9e5e-9cbedd83e586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f32e901-de33-4f24-a872-9709ffaf8678",
   "metadata": {},
   "source": [
    "**create hadoop directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b318e4ee-8b1c-4c45-8b27-bc2d61caf8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# hadoop fs -mkdir /hdfs-data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c233432d-e7f5-499c-93a2-ce733bdefe8a",
   "metadata": {},
   "source": [
    "**copy from local into hadoop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c0ca51-a456-4f76-bc47-77cda968014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# hadoop fs -copyFromLocal prepped-data/data_phone_accel.csv /hdfs-data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f654d8-030e-48c1-8b47-86fb43341cc7",
   "metadata": {},
   "source": [
    "**make sure file is in hadoop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b37352-c3d0-42e4-93a1-fe2182497af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# hadoop fs -ls /hdfs-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138f749f-af31-4b2d-b94e-f99f5c53d9d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "868e66b4",
   "metadata": {},
   "source": [
    "- Use PySpark or Dask\n",
    "- Include one classificationorregressionorclusteranalysis task\n",
    "- Describe problem\n",
    "    - To include:  Explain why problem is interesting, what real-life application is being addressed\n",
    "- Describe analysis task\n",
    "    - To include:  type of task (e.g., classification), how does task related to business problem\n",
    "- Describe data\n",
    "    - To include:  data quality issues, characteristics of the dataset (summary statistics,\n",
    "correlation, outliers, etc.), plots\n",
    "- Describe data preparation process\n",
    "    - To include:  data cleaning steps, features used, train/validation/test datasets\n",
    "- Describe analysis approaches\n",
    "    - To include:  input, setup, and output of model(s)\n",
    "- Describe challenges and solutions\n",
    "    - To include:  challenges encountered, solutions to address challenges\n",
    "- Describe analysis results and insights gained\n",
    "    - To include:  discussion of results, insights gained from analysis\n",
    "- Describe future work\n",
    "    - To include:  lessons learned, next steps, what you would have done differently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba21899",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Measures movement data over ten-second\n",
    "intervals while subjects perform the various tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9059f0",
   "metadata": {},
   "source": [
    "## Analysis approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9e5171",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5077de4a",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "\n",
    "<font color='red'>this section is wildly incomplete</font>\n",
    "\n",
    "[**sklearn - Decision Tree Regression with AdaBoost**](https://scikit-learn.org/stable/auto_examples/ensemble/plot_adaboost_regression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecf55aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_accel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370eba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN TEST SPLIT\n",
    "\n",
    "# split off labels\n",
    "feat_cols = ['x', 'y', 'z']\n",
    "label_col = ['code']\n",
    "\n",
    "feature_df = phone_accel[feat_cols]\n",
    "label_df = phone_accel[label_col]\n",
    "\n",
    "X_train, x_test, y_train, y_test = train_test_split(feature_df, label_df, test_size=0.8, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef0ee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCALE DATA\n",
    "\n",
    "# instatiate scaler\n",
    "scaler = StandardScaler()\n",
    "# fit the scaler\n",
    "scalerModel = scaler.fit(X_train)\n",
    "# scale the training data\n",
    "X_train_scaled = scalerModel.transform(X_train)\n",
    "# scale the test data\n",
    "X_test_scaled = scalerModel.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ded986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up grid search parameters\n",
    "param_grid = {'max_depth'        : list(range(1, 10)), # play around with max depth\n",
    "              'min_samples_split': list(range(2, 10)), # must start at 2+\n",
    "              'criterion'        : ['gini','entropy'],\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bf54d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRID SEARCH\n",
    "\n",
    "# instantiate base model\n",
    "dt_model = DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "# istantiate grid search object\n",
    "dt_model_grid_dask = dcv.GridSearchCV(dt_model, param_grid, cv=10)\n",
    "\n",
    "# execute grid search\n",
    "'''\n",
    "does this need joblib backend if we are using native dask?\n",
    "'''\n",
    "with joblib.parallel_backend(\"dask\"):\n",
    "    dt_model_grid_dask.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04616e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = dt_model_grid_dask.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47a6484",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dt_model_grid_dask.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600813c0-9dba-4ee5-b9e2-4d075c77113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we've performed a gridsearch, use parameters from out best model\n",
    "\n",
    "# instantiate best model\n",
    "best_dt_model = DecisionTreeClassifier(\n",
    "    max_depth=best_params['max_depth'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    criterion=best_params['criterion'],\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "# fit model to training data\n",
    "'''\n",
    "does this need joblib backend if we are using native dask?\n",
    "'''\n",
    "with joblib.parallel_backend(\"dask\"):\n",
    "    best_dt_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# check accuracy from this model on test data\n",
    "best_dt_model.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1692893",
   "metadata": {},
   "source": [
    "## Analysis results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8b598e",
   "metadata": {},
   "source": [
    "## Challenges & solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9d39c8",
   "metadata": {},
   "source": [
    "## Insights gained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ce8781",
   "metadata": {},
   "source": [
    "## Future work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b20bd37",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Dask vs spark picture: https://medium.datadriveninvestor.com/pandas-dask-or-pyspark-what-should-you-choose-for-your-dataset-c0f67e1b1d36\n",
    "2. Accelerometer information https://en.wikipedia.org/wiki/Accelerometer\n",
    "3. Gyroscope Information https://en.wikipedia.org/wiki/Gyroscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4926b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# always close client connection at end of workflow\n",
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab0876e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
